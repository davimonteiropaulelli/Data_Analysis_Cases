{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando Split tradicional\n",
    "# X\n",
    "# Validacao Cruzada (K-Fold Cross Validation)\n",
    "\n",
    "O objetivo deste exercício é aplicar a validação cruzada e comparar os resultados com a abordagem de treinamento e teste do sklearn 'train_test_split'. Acesse [aqui](https://scikit-learn.org/stable/modules/cross_validation.html) a documentação do sklearn para entender melhor sobre a implementação do K-Fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Biblioteca\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i#clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>c#default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>66155.925095</td>\n",
       "      <td>59.017015</td>\n",
       "      <td>8106.532131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34415.153966</td>\n",
       "      <td>48.117153</td>\n",
       "      <td>6564.745018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>57317.170063</td>\n",
       "      <td>63.108049</td>\n",
       "      <td>8020.953296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>42709.534201</td>\n",
       "      <td>45.751972</td>\n",
       "      <td>6103.642260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>66952.688845</td>\n",
       "      <td>18.584336</td>\n",
       "      <td>8770.099235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>59221.044874</td>\n",
       "      <td>48.518179</td>\n",
       "      <td>1926.729397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>69516.127573</td>\n",
       "      <td>23.162104</td>\n",
       "      <td>3503.176156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>44311.449262</td>\n",
       "      <td>28.017167</td>\n",
       "      <td>5522.786693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>43756.056605</td>\n",
       "      <td>63.971796</td>\n",
       "      <td>1622.722598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>69436.579552</td>\n",
       "      <td>56.152617</td>\n",
       "      <td>7378.833599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1997 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      i#clientid        income        age         loan  c#default\n",
       "0              1  66155.925095  59.017015  8106.532131          0\n",
       "1              2  34415.153966  48.117153  6564.745018          0\n",
       "2              3  57317.170063  63.108049  8020.953296          0\n",
       "3              4  42709.534201  45.751972  6103.642260          0\n",
       "4              5  66952.688845  18.584336  8770.099235          1\n",
       "...          ...           ...        ...          ...        ...\n",
       "1995        1996  59221.044874  48.518179  1926.729397          0\n",
       "1996        1997  69516.127573  23.162104  3503.176156          0\n",
       "1997        1998  44311.449262  28.017167  5522.786693          1\n",
       "1998        1999  43756.056605  63.971796  1622.722598          0\n",
       "1999        2000  69436.579552  56.152617  7378.833599          0\n",
       "\n",
       "[1997 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Arquivo\n",
    "df = pd.read_csv('credit_data.csv')\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criacao das variaveis x e y\n",
    "x = df.drop(['i#clientid','c#default'],axis=1).values\n",
    "y = df['c#default'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split tradicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento dos Modelos (30 vezes cada modelo)\n",
    "resultados_Naive_bayes = []\n",
    "resultados_logistic = []\n",
    "resultados_forest = []\n",
    "for i in range(30):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,\n",
    "                                                       test_size = 0.2,\n",
    "                                                       stratify = y, random_state = i)\n",
    "    \n",
    "    naive_bayes = GaussianNB()\n",
    "    naive_bayes.fit(x_train, y_train)\n",
    "    resultados_Naive_bayes.append(accuracy_score(y_test, naive_bayes.predict(x_test)))\n",
    "    \n",
    "    logistic = LogisticRegression()\n",
    "    logistic.fit(x_train, y_train)\n",
    "    resultados_logistic.append(accuracy_score(y_test, logistic.predict(x_test)))\n",
    "    \n",
    "    forest = RandomForestClassifier()\n",
    "    forest.fit(x_train, y_train)\n",
    "    resultados_forest.append(accuracy_score(y_test, forest.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando array dos resultados para aplicacao e verificacao da medias\n",
    "resultados_Naive_bayes = np.array(resultados_Naive_bayes)\n",
    "resultados_logistic = np.array(resultados_logistic)\n",
    "resultados_forest = np.array(resultados_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posicao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media acuracia dos resultados do Naive Bayes:  0.92425 \n",
      "Media acuracia dos resultados da Regressao logistica:  0.9145 \n",
      "Media acuracia dos resultados da Floresta aleatoria:  0.9838333333333332\n"
     ]
    }
   ],
   "source": [
    "# Media Aritmetica dos treinamentos de cada modelo\n",
    "print('Media acuracia dos resultados do Naive Bayes: ',resultados_Naive_bayes.mean(), \n",
    "      '\\nMedia acuracia dos resultados da Regressao logistica: ', resultados_logistic.mean(), \n",
    "      '\\nMedia acuracia dos resultados da Floresta aleatoria: ',resultados_forest.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moda acuracia e frequencia dos resultados do Naive Bayes:  ModeResult(mode=array([0.9175]), count=array([5])) \n",
      "Moda acuracia e frequencia dos resultados da Regressao logistica:  ModeResult(mode=array([0.9075]), count=array([4])) \n",
      "Moda acuracia e frequencia dos resultados da Floresta aleatoria:  ModeResult(mode=array([0.985]), count=array([6]))\n"
     ]
    }
   ],
   "source": [
    "# Moda dos treinamentos\n",
    "print('Moda acuracia e frequencia dos resultados do Naive Bayes: ',stats.mode(resultados_Naive_bayes),\n",
    "      '\\nModa acuracia e frequencia dos resultados da Regressao logistica: ', stats.mode(resultados_logistic), \n",
    "      '\\nModa acuracia e frequencia dos resultados da Floresta aleatoria: ',stats.mode(resultados_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediana acuracia dos resultados do Naive Bayes:  0.925 \n",
      "Mediana acuracia dos resultados da Regressao logistica:  0.9125 \n",
      "Mediana acuracia dos resultados da Floresta aleatoria:  0.985\n"
     ]
    }
   ],
   "source": [
    "# Mediana dos mesmos\n",
    "print('Mediana acuracia dos resultados do Naive Bayes: ',np.median(resultados_Naive_bayes),\n",
    "      '\\nMediana acuracia dos resultados da Regressao logistica: ', np.median(resultados_logistic), \n",
    "      '\\nMediana acuracia dos resultados da Floresta aleatoria: ',np.median(resultados_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuicao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variancia do Naive Bayes:  8.756250000000001e-05 \n",
      "Variancia da Regressao Logistica:  0.00020933333333333337 \n",
      "Variancia da Floresta aleatoria:  3.613888888888892e-05\n",
      "\n",
      "\n",
      "Destas apresentadas, o algoritimo que possui menor variancia e' o Random Forest com:  3.613888888888892e-05\n"
     ]
    }
   ],
   "source": [
    "# Variancia\n",
    "print('Variancia do Naive Bayes: ',np.var(resultados_Naive_bayes), \n",
    "      '\\nVariancia da Regressao Logistica: ',np.var(resultados_logistic), \n",
    "      '\\nVariancia da Floresta aleatoria: ',np.var(resultados_forest))\n",
    "print(\"\\n\\nDestas apresentadas, o algoritimo que possui menor variancia e' o Random Forest com: \",min(np.var(resultados_Naive_bayes), np.var(resultados_logistic), np.var(resultados_forest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desvio Padrao do Naive Bayes:  0.00935748363610645 \n",
      "Desvio Padrao da Regressao Logistica:  0.014468356276140472 \n",
      "Desvio Padrao da Floresta aleatoria:  0.006011562932290481\n"
     ]
    }
   ],
   "source": [
    "# Desvio Padrao\n",
    "print('Desvio Padrao do Naive Bayes: ',np.std(resultados_Naive_bayes), \n",
    "      '\\nDesvio Padrao da Regressao Logistica: ',np.std(resultados_logistic), \n",
    "      '\\nDesvio Padrao da Floresta aleatoria: ',np.std(resultados_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficiente de Variacao do Naive Bayes:  1.0124407504578252 \n",
      "Coeficiente de Variacao da Regressao Logistica:  1.5821056616884057 \n",
      "Coeficiente de Variacao da Floresta aleatoria:  0.611034687341062\n"
     ]
    }
   ],
   "source": [
    "# Coeficiente de Variacao\n",
    "print('Coeficiente de Variacao do Naive Bayes: ',stats.variation(resultados_Naive_bayes)*100, \n",
    "      '\\nCoeficiente de Variacao da Regressao Logistica: ',stats.variation(resultados_logistic)*100, \n",
    "      '\\nCoeficiente de Variacao da Floresta aleatoria: ',stats.variation(resultados_forest)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validacao Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento dos Modelos (30 vezes cada modelo)\n",
    "resultados_Naive_bayes_cv = []\n",
    "resultados_logistic_cv = []\n",
    "resultados_forest_cv = []\n",
    "for i in range(30):\n",
    "    kFold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    naive_bayes = GaussianNB()\n",
    "    scores = cross_val_score(naive_bayes,x,y,cv = kFold)\n",
    "    resultados_Naive_bayes_cv.append(scores.mean())\n",
    "    \n",
    "    logistic = LogisticRegression()\n",
    "    scores = cross_val_score(logistic,x,y,cv = kFold)\n",
    "    resultados_logistic_cv.append(scores.mean())\n",
    "    \n",
    "    forest = RandomForestClassifier()\n",
    "    scores = cross_val_score(forest,x,y,cv = kFold)\n",
    "    resultados_forest_cv.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficiente de Variacao do Naive Bayes Split:  1.0124407504578252 \n",
      "Coeficiente de Variacao do Naive Bayes Valid. Cruzada:  0.08641071566366061 \n",
      "\n",
      "Coeficiente de Variacao da Regressao Logistica Split:  1.5821056616884057 \n",
      "Coeficiente de Variacao da Regressao Logistica Valid. Cruzada:  0.38801026116292653 \n",
      "\n",
      "Coeficiente de Variacao da Floresta aleatoria Split:  0.611034687341062 \n",
      "Coeficiente de Variacao da Floresta aleatoria Valid. Cruzada:  0.1472123579609125\n"
     ]
    }
   ],
   "source": [
    "# Comparando\n",
    "print('Coeficiente de Variacao do Naive Bayes Split: ',stats.variation(resultados_Naive_bayes)*100, \n",
    "      '\\nCoeficiente de Variacao do Naive Bayes Valid. Cruzada: ',stats.variation(resultados_Naive_bayes_cv)*100,\n",
    "      '\\n\\nCoeficiente de Variacao da Regressao Logistica Split: ',stats.variation(resultados_logistic)*100, \n",
    "      '\\nCoeficiente de Variacao da Regressao Logistica Valid. Cruzada: ',stats.variation(resultados_logistic_cv)*100, \n",
    "      '\\n\\nCoeficiente de Variacao da Floresta aleatoria Split: ',stats.variation(resultados_forest)*100,\n",
    "      '\\nCoeficiente de Variacao da Floresta aleatoria Valid. Cruzada: ',stats.variation(resultados_forest_cv)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que com o metodo de validacao cruzada a varianca caiu significativamente, portanto, e' a melhor solucao quando se busca uma solucao mais acertiva (com menor variancia)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
